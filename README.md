# SIGN SPEAK: Indian Sign Language Recognition System

## Project Overview
SIGN SPEAK is a comprehensive system developed for recognizing Indian Sign Language (ISL) using video input. The project utilizes advanced machine learning techniques to interpret signs in real-time, translating them into text and speech. This application is designed to facilitate communication for the hearing impaired community by bridging the gap between sign language and spoken language.

### Key Features
- **Real-time Sign Language Detection**: Uses video input for immediate recognition of signs.
- **Key Point Extraction**: Employs Mediapipe for extracting key points from hand gestures.
- **LSTM Neural Network**: Utilizes a trained Long Short-Term Memory (LSTM) model for accurate predictions.
- **Text and Speech Output**: Converts recognized signs into text and audible speech, enhancing accessibility.

## Technologies Used
- **Languages**: Python
- **Libraries**: 
  - TensorFlow
  - Keras
  - OpenCV
  - Mediapipe
  - NumPy
  - Matplotlib
  - Seaborn
  - Scikit-learn
  - Gradio

## Live Demo
You can try the live demo of the project on Hugging Face: [SIGN SPEAK Live Demo](https://huggingface.co/spaces/sandeepa-TN/Sign_Speak_MCE2)
